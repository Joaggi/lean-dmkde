{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python388jvsc74a57bd06f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1",
      "display_name": "Python 3.8.8 64-bit ('tf_x86': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "6f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1"
      }
    },
    "colab": {
      "name": "TPU-QM-DM-mnist.ipynb",
      "provenance": []
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SovY65Wo9LhM"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fagonzalezo/qmc/blob/master/examples/TPU-QM-DM-mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLf3P_V29LhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcc4664a-2027-49d6-b5f4-0be4a7e1b68d"
      },
      "source": [
        "# Install qmc if running in Google Colab\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install --upgrade  git+https://github.com/fagonzalezo/qmc.git\n",
        "else:\n",
        "    import sys\n",
        "    sys.path.insert(0, \"../\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/fagonzalezo/qmc.git\n",
            "  Cloning https://github.com/fagonzalezo/qmc.git to /tmp/pip-req-build-vwbdkirz\n",
            "  Running command git clone -q https://github.com/fagonzalezo/qmc.git /tmp/pip-req-build-vwbdkirz\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.19.2 in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typeguard in /usr/local/lib/python3.7/dist-packages (from qmc==0.0.1) (2.7.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->qmc==0.0.1) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.2.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (3.12.4)\n",
            "Requirement already satisfied, skipping upgrade: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.32.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.12)\n",
            "Requirement already satisfied, skipping upgrade: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.36.2)\n",
            "Requirement already satisfied, skipping upgrade: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.6.3)\n",
            "Requirement already satisfied, skipping upgrade: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (3.3.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (0.12.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.2.0->qmc==0.0.1) (2.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=2.2.0->qmc==0.0.1) (56.1.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.3.4)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.8.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (0.4.4)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.10.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (4.2.1)\n",
            "Requirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (4.7.2)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=2.2.0->qmc==0.0.1) (3.1.0)\n",
            "Building wheels for collected packages: qmc\n",
            "  Building wheel for qmc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for qmc: filename=qmc-0.0.1-cp37-none-any.whl size=11811 sha256=92bfe2aac56930e57e47df8e7ea8b28b942ee04a6efa9716b58684fc7ae5cc73\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2nu_8mvv/wheels/ff/c2/53/58cb50bb85949fb1dcda723a7c1f48a590515dee0aa40a4cc2\n",
            "Successfully built qmc\n",
            "Installing collected packages: qmc\n",
            "  Found existing installation: qmc 0.0.1\n",
            "    Uninstalling qmc-0.0.1:\n",
            "      Successfully uninstalled qmc-0.0.1\n",
            "Successfully installed qmc-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmwZ_WBj9lq_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import qmc.tf.layers as layers\n",
        "import qmc.tf.models as models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO7oEcqA-qNP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33111603-8b69-46e4-f55f-9b6e7b99b2ff"
      },
      "source": [
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.31.33.242:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.31.33.242:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.31.33.242:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyfGmmgd9dyL"
      },
      "source": [
        "BATCH_SIZE = 64 * tpu_strategy.num_replicas_in_sync\n",
        "training_images_file   = 'gs://mnist-public/train-images-idx3-ubyte'\n",
        "training_labels_file   = 'gs://mnist-public/train-labels-idx1-ubyte'\n",
        "validation_images_file = 'gs://mnist-public/t10k-images-idx3-ubyte'\n",
        "validation_labels_file = 'gs://mnist-public/t10k-labels-idx1-ubyte'\n",
        "def read_label(tf_bytestring):\n",
        "    label = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    label = tf.reshape(label, [])\n",
        "    label = tf.one_hot(label, 10)\n",
        "    return label\n",
        "  \n",
        "def read_image(tf_bytestring):\n",
        "    image = tf.io.decode_raw(tf_bytestring, tf.uint8)\n",
        "    image = tf.cast(image, tf.float32)/256.0\n",
        "    image = tf.reshape(image, [28*28])\n",
        "    return image\n",
        "  \n",
        "def load_dataset(image_file, label_file):\n",
        "    imagedataset = tf.data.FixedLengthRecordDataset(image_file, 28*28, header_bytes=16)\n",
        "    imagedataset = imagedataset.map(read_image, num_parallel_calls=16)\n",
        "    labelsdataset = tf.data.FixedLengthRecordDataset(label_file, 1, header_bytes=8)\n",
        "    labelsdataset = labelsdataset.map(read_label, num_parallel_calls=16)\n",
        "    dataset = tf.data.Dataset.zip((imagedataset, labelsdataset))\n",
        "    return dataset \n",
        "  \n",
        "def get_training_dataset(image_file, label_file, batch_size):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache()  # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.shuffle(5000, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(-1)  # fetch next batches while training on the current one (-1: autotune prefetch buffer size)\n",
        "    return dataset\n",
        "  \n",
        "def get_validation_dataset(image_file, label_file):\n",
        "    dataset = load_dataset(image_file, label_file)\n",
        "    dataset = dataset.cache() # this small dataset can be entirely cached in RAM\n",
        "    dataset = dataset.batch(10000)\n",
        "    return dataset\n",
        "\n",
        "# instantiate the datasets\n",
        "training_dataset = get_training_dataset(training_images_file, training_labels_file, BATCH_SIZE)\n",
        "validation_dataset = get_validation_dataset(validation_images_file, validation_labels_file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsNNXRvi92TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13569788-2240-4107-fcf9-bc6ba096841c"
      },
      "source": [
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.Softmax()\n",
        "    ])\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "        metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
        "    )\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "  \n",
        "history = model.fit(training_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  117\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_3_input'), name='flatten_3_input', description=\"created by layer 'flatten_3_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_3_input'), name='flatten_3_input', description=\"created by layer 'flatten_3_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_3_input'), name='flatten_3_input', description=\"created by layer 'flatten_3_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_3_input'), name='flatten_3_input', description=\"created by layer 'flatten_3_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "117/117 [==============================] - ETA: 0s - loss: 1.0396 - categorical_accuracy: 0.7108WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_3_input'), name='flatten_3_input', description=\"created by layer 'flatten_3_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 28, 28) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28), dtype=tf.float32, name='flatten_3_input'), name='flatten_3_input', description=\"created by layer 'flatten_3_input'\"), but it was called on an input with incompatible shape (None, 784).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "117/117 [==============================] - 5s 28ms/step - loss: 1.0358 - categorical_accuracy: 0.7119 - val_loss: 0.2807 - val_categorical_accuracy: 0.9227\n",
            "Epoch 2/10\n",
            "117/117 [==============================] - 3s 25ms/step - loss: 0.2689 - categorical_accuracy: 0.9259 - val_loss: 0.2147 - val_categorical_accuracy: 0.9390\n",
            "Epoch 3/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.2063 - categorical_accuracy: 0.9418 - val_loss: 0.1821 - val_categorical_accuracy: 0.9480\n",
            "Epoch 4/10\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1695 - categorical_accuracy: 0.9515 - val_loss: 0.1580 - val_categorical_accuracy: 0.9552\n",
            "Epoch 5/10\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1455 - categorical_accuracy: 0.9589 - val_loss: 0.1390 - val_categorical_accuracy: 0.9606\n",
            "Epoch 6/10\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.1253 - categorical_accuracy: 0.9646 - val_loss: 0.1263 - val_categorical_accuracy: 0.9631\n",
            "Epoch 7/10\n",
            "117/117 [==============================] - 2s 19ms/step - loss: 0.1089 - categorical_accuracy: 0.9689 - val_loss: 0.1148 - val_categorical_accuracy: 0.9666\n",
            "Epoch 8/10\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0960 - categorical_accuracy: 0.9724 - val_loss: 0.1068 - val_categorical_accuracy: 0.9687\n",
            "Epoch 9/10\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0855 - categorical_accuracy: 0.9757 - val_loss: 0.1012 - val_categorical_accuracy: 0.9696\n",
            "Epoch 10/10\n",
            "117/117 [==============================] - 2s 20ms/step - loss: 0.0760 - categorical_accuracy: 0.9787 - val_loss: 0.0979 - val_categorical_accuracy: 0.9709\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOte8WRc999W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad289207-87ec-4737-ca0e-7b140ff93b77"
      },
      "source": [
        "input_dim = 784\n",
        "component_dim = 128\n",
        "gamma = 2**-5\n",
        "num_eig = 128\n",
        "random_state = 0\n",
        "LEARNING_RATE = 0.004\n",
        "LEARNING_RATE_EXP_DECAY = 0.6 if tpu_strategy.num_replicas_in_sync == 1 else 0.7\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
        "    verbose=True)\n",
        "\n",
        "with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "    inputs = tf.keras.Input(shape=(784,))\n",
        "    fm_x = layers.QFeatureMapRFF(784, dim=component_dim , gamma=gamma, random_state=random_state)\n",
        "    psi_x = fm_x(inputs)\n",
        "    ones = tf.ones_like(inputs[:, 0:1])\n",
        "    rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "    rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "    qmdmc = layers.QMeasureDMClassifEig(dim_x=component_dim , dim_y=10, eig_out=num_eig // 10, num_eig=num_eig)\n",
        "    rho_y = qmdmc(rho_x)\n",
        "    y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "    y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "    probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v))\n",
        "    qmdmclf = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.0001, decay=1e-6)\n",
        "    qmdmclf.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "  \n",
        "history = qmdmclf.fit(training_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1,\n",
        "                    callbacks=[lr_decay])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  117\n",
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.004.\n",
            "117/117 [==============================] - 9s 39ms/step - loss: 1.7407 - accuracy: 0.4969 - val_loss: 0.9724 - val_accuracy: 0.8501\n",
            "Epoch 2/10\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.0028.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.9490 - accuracy: 0.8586 - val_loss: 0.8807 - val_accuracy: 0.8838\n",
            "Epoch 3/10\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.00196.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.8669 - accuracy: 0.8879 - val_loss: 0.8479 - val_accuracy: 0.8923\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0013719999999999997.\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.8317 - accuracy: 0.9033 - val_loss: 0.8308 - val_accuracy: 0.8884\n",
            "Epoch 5/10\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0009603999999999998.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.8178 - accuracy: 0.8971 - val_loss: 0.8196 - val_accuracy: 0.8952\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0006722799999999998.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.8053 - accuracy: 0.9044 - val_loss: 0.8209 - val_accuracy: 0.9034\n",
            "Epoch 7/10\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 0.0004705959999999999.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.8012 - accuracy: 0.9133 - val_loss: 0.8146 - val_accuracy: 0.9076\n",
            "Epoch 8/10\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 0.0003294171999999999.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.7942 - accuracy: 0.9150 - val_loss: 0.8126 - val_accuracy: 0.9059\n",
            "Epoch 9/10\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 0.0002305920399999999.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.7915 - accuracy: 0.9162 - val_loss: 0.8095 - val_accuracy: 0.9006\n",
            "Epoch 10/10\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 0.0001614144279999999.\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.7892 - accuracy: 0.9103 - val_loss: 0.8103 - val_accuracy: 0.9026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrZ2k0KLHxus",
        "outputId": "8bae52f4-150d-42ea-d7f2-fc4ddd8cffa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_dim = 784\n",
        "component_dim = 128\n",
        "gamma = 2**-5\n",
        "num_eig = 128\n",
        "random_state = 0\n",
        "LEARNING_RATE = 0.001\n",
        "LEARNING_RATE_EXP_DECAY = 0.6 if tpu_strategy.num_replicas_in_sync == 1 else 0.7\n",
        "lr_decay = tf.keras.callbacks.LearningRateScheduler(\n",
        "    lambda epoch: LEARNING_RATE * LEARNING_RATE_EXP_DECAY**epoch,\n",
        "    verbose=True)\n",
        "\n",
        "with tpu_strategy.scope(): \n",
        "    inputs = tf.keras.Input(shape=(784,))\n",
        "    fm_x1 = layers.QFeatureMapRFF(784, dim=component_dim , gamma=gamma, random_state=random_state)\n",
        "    psi_x = fm_x1(inputs)\n",
        "    ones = tf.ones_like(inputs[:, 0:1])\n",
        "    rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "    rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "    qmdmc1 = layers.QMeasureDMClassifEig(dim_x=component_dim , dim_y=10, eig_out=num_eig // 10, num_eig=num_eig)\n",
        "    rho_h = qmdmc1(rho_x)\n",
        "    qmdmc2 = layers.QMeasureDMClassifEig(dim_x=10 , dim_y=10, eig_out=10, num_eig=10)\n",
        "    rho_y = qmdmc2(rho_h)\n",
        "    y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "    y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "    probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v))\n",
        "    qmdmclf2 = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
        "    qmdmclf2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "fm_x1.set_weights(fm_x.get_weights())\n",
        "fm_x1.trainable = False\n",
        "qmdmc1.set_rho(qmdmc.get_rho())\n",
        "qmdmc1.trainable = False\n",
        "EPOCHS = 10\n",
        "steps_per_epoch = 60000//BATCH_SIZE  # 60,000 items in this dataset\n",
        "print(\"Steps per epoch: \", steps_per_epoch)\n",
        "  \n",
        "history = qmdmclf2.fit(training_dataset,\n",
        "                    steps_per_epoch=steps_per_epoch, epochs=EPOCHS,\n",
        "                    validation_data=validation_dataset, validation_steps=1, )\n",
        "#                    callbacks=[lr_decay])"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Steps per epoch:  117\n",
            "Epoch 1/10\n",
            "117/117 [==============================] - 14s 56ms/step - loss: 2.0220 - accuracy: 0.3398 - val_loss: 1.3194 - val_accuracy: 0.7304\n",
            "Epoch 2/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 1.2232 - accuracy: 0.7712 - val_loss: 1.0075 - val_accuracy: 0.8085\n",
            "Epoch 3/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.9885 - accuracy: 0.8221 - val_loss: 0.9440 - val_accuracy: 0.8106\n",
            "Epoch 4/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.9250 - accuracy: 0.8383 - val_loss: 0.9601 - val_accuracy: 0.7430\n",
            "Epoch 5/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.9071 - accuracy: 0.7880 - val_loss: 0.8822 - val_accuracy: 0.8436\n",
            "Epoch 6/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.8912 - accuracy: 0.8501 - val_loss: 0.8582 - val_accuracy: 0.8443\n",
            "Epoch 7/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.8494 - accuracy: 0.8508 - val_loss: 0.8213 - val_accuracy: 0.8435\n",
            "Epoch 8/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.8085 - accuracy: 0.8198 - val_loss: 0.8049 - val_accuracy: 0.8505\n",
            "Epoch 9/10\n",
            "117/117 [==============================] - 3s 24ms/step - loss: 0.7989 - accuracy: 0.8544 - val_loss: 0.8086 - val_accuracy: 0.8576\n",
            "Epoch 10/10\n",
            "117/117 [==============================] - 3s 23ms/step - loss: 0.7748 - accuracy: 0.8461 - val_loss: 0.7810 - val_accuracy: 0.8490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmn69C0JKL-"
      },
      "source": [
        ""
      ],
      "execution_count": 81,
      "outputs": []
    }
  ]
}