{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python388jvsc74a57bd06f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1",
      "display_name": "Python 3.8.8 64-bit ('tf_x86': conda)"
    },
    "metadata": {
      "interpreter": {
        "hash": "6f5c4f860b8b5392c9fe536844a7572c0d9b36e44085495c747ab5a91e5f3cc1"
      }
    },
    "colab": {
      "name": "GPU-QM-DM-mnist.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fagonzalezo/qmc/blob/master/examples/QMC_Multimodal_Mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLf3P_V29LhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3395e4f0-171d-4616-ed3a-7804162229c9"
      },
      "source": [
        "# Install qmc if running in Google Colab\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    !pip install --upgrade  git+https://github.com/fagonzalezo/qmc.git\n",
        "else:\n",
        "    import sys\n",
        "    sys.path.insert(0, \"../\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmwZ_WBj9lq_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import qmc.tf.layers as layers\n",
        "import qmc.tf.models as models"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyLwyfpqxN7M",
        "outputId": "8178e742-560b-41da-fbf2-dda968d76172"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape((60000,784))\n",
        "X_test = X_test.reshape((10000,784))\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "transformer = OneHotEncoder(sparse=False)\n",
        "y_train_bin = transformer.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_bin = transformer.fit_transform(y_test[:, np.newaxis])\n",
        "\n",
        "print(\"shape X_train : \", X_train.shape)\n",
        "print(\"shape y_train : \", y_train.shape)\n",
        "print(\"shape X_test : \", X_test.shape)\n",
        "print(\"shape y_test : \", y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape X_train :  (60000, 784)\nshape y_train :  (60000,)\nshape X_test :  (10000, 784)\nshape y_test :  (10000,)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Baseline"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsNNXRvi92TV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8a67bbc-2f1c-4857-92c8-78f1c3fc11f5"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "tf.keras.layers.Dense(128,activation='relu'),\n",
        "tf.keras.layers.Dense(10),\n",
        "tf.keras.layers.Softmax()\n",
        "])\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "    metrics=[tf.keras.metrics.CategoricalAccuracy()],\n",
        ")\n",
        "EPOCHS = 10\n",
        "  \n",
        "history = model.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.8690 - categorical_accuracy: 0.7577 - val_loss: 0.2460 - val_categorical_accuracy: 0.9333\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.2367 - categorical_accuracy: 0.9331 - val_loss: 0.1793 - val_categorical_accuracy: 0.9519\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.1683 - categorical_accuracy: 0.9523 - val_loss: 0.1618 - val_categorical_accuracy: 0.9547\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.1322 - categorical_accuracy: 0.9621 - val_loss: 0.1334 - val_categorical_accuracy: 0.9614\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 0s 3ms/step - loss: 0.1078 - categorical_accuracy: 0.9706 - val_loss: 0.1207 - val_categorical_accuracy: 0.9651\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0927 - categorical_accuracy: 0.9739 - val_loss: 0.1116 - val_categorical_accuracy: 0.9665\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0765 - categorical_accuracy: 0.9790 - val_loss: 0.1031 - val_categorical_accuracy: 0.9691\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0672 - categorical_accuracy: 0.9803 - val_loss: 0.0972 - val_categorical_accuracy: 0.9713\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0578 - categorical_accuracy: 0.9845 - val_loss: 0.0960 - val_categorical_accuracy: 0.9711\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 0s 2ms/step - loss: 0.0527 - categorical_accuracy: 0.9855 - val_loss: 0.0933 - val_categorical_accuracy: 0.9706\n"
          ]
        }
      ]
    },
    {
      "source": [
        "## Half model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWmn69C0JKL-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d82d510-4c0a-4515-f95a-e712fff80a62"
      },
      "source": [
        "BATCH_SIZE = 256\n",
        "def create_model(input_dim,\n",
        "               output_dim,\n",
        "               num_rff = 512,\n",
        "               gamma = 2**-5,\n",
        "               n_comp = 80,\n",
        "               random_state = 0):\n",
        "    inputs = tf.keras.Input(shape=(input_dim,))\n",
        "    fm_x1 = layers.QFeatureMapRFF(input_dim, dim=num_rff , gamma=gamma, random_state=random_state)\n",
        "    psi_x = fm_x1(inputs)\n",
        "    ones = tf.ones_like(inputs[:, 0:1])\n",
        "    rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "    rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "    qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=num_rff, dim_y=output_dim, n_comp=n_comp)\n",
        "    rho_y = qmdmc(rho_x)\n",
        "    y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "    y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "    probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v), optimize='optimal')\n",
        "    qmdmclf = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "    return qmdmclf\n",
        "\n",
        "def create_model_rho(input_dim,\n",
        "               output_dim,\n",
        "               num_rff = 512,\n",
        "               gamma = 2**-5,\n",
        "               n_comp = 80,\n",
        "               random_state = 0):\n",
        "    inputs = tf.keras.Input(shape=(input_dim,))\n",
        "    fm_x1 = layers.QFeatureMapRFF(input_dim, dim=num_rff , gamma=gamma, random_state=random_state)\n",
        "    psi_x = fm_x1(inputs)\n",
        "    ones = tf.ones_like(inputs[:, 0:1])\n",
        "    rho_x = tf.keras.layers.concatenate((ones, psi_x), axis=1)\n",
        "    rho_x = tf.expand_dims(rho_x, axis=-1)\n",
        "    qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=num_rff, dim_y=output_dim, n_comp=n_comp)\n",
        "    rho_y = qmdmc(rho_x)\n",
        "    qmdmclf = tf.keras.Model(inputs=inputs, outputs=rho_y)\n",
        "    return qmdmclf\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 1.5393 - accuracy: 0.5709 - val_loss: 0.6130 - val_accuracy: 0.8671\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.5562 - accuracy: 0.8702 - val_loss: 0.4531 - val_accuracy: 0.8948\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.4273 - accuracy: 0.8983 - val_loss: 0.4118 - val_accuracy: 0.9048\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3795 - accuracy: 0.9054 - val_loss: 0.3874 - val_accuracy: 0.9099\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3480 - accuracy: 0.9147 - val_loss: 0.3701 - val_accuracy: 0.9134\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3251 - accuracy: 0.9194 - val_loss: 0.3535 - val_accuracy: 0.9161\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3091 - accuracy: 0.9239 - val_loss: 0.3455 - val_accuracy: 0.9196\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2898 - accuracy: 0.9283 - val_loss: 0.3380 - val_accuracy: 0.9212\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2765 - accuracy: 0.9327 - val_loss: 0.3284 - val_accuracy: 0.9225\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.2750 - accuracy: 0.9310 - val_loss: 0.3225 - val_accuracy: 0.9245\n"
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "qmdmclf_1 = create_model(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "qmdmclf_1.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 256  \n",
        "history = qmdmclf_1.fit(X_train[:, 0:784 // 2], y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 2s 8ms/step - loss: 1.0416 - accuracy: 0.6906 - val_loss: 0.4646 - val_accuracy: 0.8661\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.4343 - accuracy: 0.8704 - val_loss: 0.4199 - val_accuracy: 0.8758\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3798 - accuracy: 0.8849 - val_loss: 0.3971 - val_accuracy: 0.8826\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3535 - accuracy: 0.8903 - val_loss: 0.3752 - val_accuracy: 0.8857\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3334 - accuracy: 0.8950 - val_loss: 0.3667 - val_accuracy: 0.8878\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3197 - accuracy: 0.9021 - val_loss: 0.3625 - val_accuracy: 0.8897\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3104 - accuracy: 0.9062 - val_loss: 0.3570 - val_accuracy: 0.8903\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 1s 7ms/step - loss: 0.3039 - accuracy: 0.9067 - val_loss: 0.3544 - val_accuracy: 0.8921\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.2938 - accuracy: 0.9117 - val_loss: 0.3471 - val_accuracy: 0.8937\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 1s 8ms/step - loss: 0.2858 - accuracy: 0.9124 - val_loss: 0.3477 - val_accuracy: 0.8935\n"
          ]
        }
      ],
      "source": [
        "qmdmclf_2 = create_model(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "qmdmclf_2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "history = qmdmclf_2.fit(X_train[:, 784 // 2:], y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ]
    },
    {
      "source": [
        "## Multimodal model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(784,))\n",
        "clf_1 = create_model_rho(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "clf_2 = create_model_rho(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "rho_1 = clf_1(inputs[:, :784 // 2])\n",
        "rho_2 = clf_2(inputs[:, 784 // 2:])\n",
        "prod = layers.DMCrossProduct()([rho_1, rho_2])\n",
        "qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=100, dim_y=10, n_comp=40)\n",
        "rho_y = qmdmc(prod)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v), optimize='optimal')\n",
        "qm_multim = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "188/188 [==============================] - 25s 125ms/step - loss: 0.8980 - accuracy: 0.7620 - val_loss: 0.2550 - val_accuracy: 0.9473\n",
            "Epoch 2/10\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.2256 - accuracy: 0.9552 - val_loss: 0.2184 - val_accuracy: 0.9541\n",
            "Epoch 3/10\n",
            "188/188 [==============================] - 23s 122ms/step - loss: 0.1875 - accuracy: 0.9627 - val_loss: 0.1994 - val_accuracy: 0.9578\n",
            "Epoch 4/10\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1632 - accuracy: 0.9695 - val_loss: 0.1887 - val_accuracy: 0.9601\n",
            "Epoch 5/10\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.1459 - accuracy: 0.9740 - val_loss: 0.1811 - val_accuracy: 0.9610\n",
            "Epoch 6/10\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.1322 - accuracy: 0.9776 - val_loss: 0.1777 - val_accuracy: 0.9631\n",
            "Epoch 7/10\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.1234 - accuracy: 0.9802 - val_loss: 0.1740 - val_accuracy: 0.9629\n",
            "Epoch 8/10\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1191 - accuracy: 0.9814 - val_loss: 0.1717 - val_accuracy: 0.9638\n",
            "Epoch 9/10\n",
            "188/188 [==============================] - 24s 126ms/step - loss: 0.1124 - accuracy: 0.9824 - val_loss: 0.1711 - val_accuracy: 0.9635\n",
            "Epoch 10/10\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1053 - accuracy: 0.9843 - val_loss: 0.1684 - val_accuracy: 0.9647\n"
          ]
        }
      ],
      "source": [
        "qm_multim.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 10\n",
        "history = qm_multim.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_3 (InputLayer)            [(None, 784)]        0                                            \n__________________________________________________________________________________________________\ntf.__operators__.getitem_8 (Sli (None, 392)          0           input_3[0][0]                    \n__________________________________________________________________________________________________\ntf.__operators__.getitem_9 (Sli (None, 392)          0           input_3[0][0]                    \n__________________________________________________________________________________________________\nmodel_2 (Functional)            (None, 11, 10)       103278      tf.__operators__.getitem_8[0][0] \n__________________________________________________________________________________________________\nmodel_3 (Functional)            (None, 11, 10)       103278      tf.__operators__.getitem_9[0][0] \n__________________________________________________________________________________________________\ndm_cross_product (DMCrossProduc (None, None, None)   0           model_2[0][0]                    \n                                                                 model_3[0][0]                    \n__________________________________________________________________________________________________\nqm_classif_s_decomp_fd_matrix_4 (None, 11, 40)       4440        dm_cross_product[0][0]           \n__________________________________________________________________________________________________\ntf.__operators__.getitem_11 (Sl (None, 10, 40)       0           qm_classif_s_decomp_fd_matrix_4[0\n__________________________________________________________________________________________________\ntf.__operators__.getitem_10 (Sl (None, 40)           0           qm_classif_s_decomp_fd_matrix_4[0\n__________________________________________________________________________________________________\ntf.math.conj_2 (TFOpLambda)     (None, 10, 40)       0           tf.__operators__.getitem_11[0][0]\n__________________________________________________________________________________________________\ntf.einsum_2 (TFOpLambda)        (None, 10)           0           tf.__operators__.getitem_10[0][0]\n                                                                 tf.__operators__.getitem_11[0][0]\n                                                                 tf.math.conj_2[0][0]             \n==================================================================================================\nTotal params: 210,996\nTrainable params: 210,996\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "qm_multim.summary()"
      ]
    },
    {
      "source": [
        "## Noisy dataset"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 0s 482us/step - loss: 9.7003 - categorical_accuracy: 0.2244\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9.70030689239502, 0.22439999878406525]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "X_test_noise = np.array(X_test)\n",
        "X_test_noise[:, :784 // 2] =  np.random.uniform(size=X_test.shape)[:, :784 // 2]\n",
        "model.evaluate(X_test_noise, y_test_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 1.6451 - accuracy: 0.3966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6450669765472412, 0.39660000801086426]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "qm_multim.evaluate(X_test_noise, y_test_bin)"
      ]
    },
    {
      "source": [
        "## Partial model"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(784,))\n",
        "clf_1 = create_model_rho(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "rho_1 = clf_1(inputs[:, :784 // 2])\n",
        "rho_in = tf.keras.layers.concatenate((tf.ones((1, 256)) / 256., tf.eye(256)), axis = 0)\n",
        "rho_in = tf.expand_dims(rho_in, axis=0)\n",
        "clf_2 = layers.QMClassifSDecompFDMatrix(dim_x=256, dim_y=10, n_comp=20, name=\"clf_2\")\n",
        "clf_2(rho_in)\n",
        "clf_2.set_weights(qm_multim.layers[4].layers[-1].get_weights())\n",
        "rho_2 = clf_2(rho_in)\n",
        "#rho_2 = tf.keras.layers.concatenate((rho_2, tf.zeros((11, 10))), axis=1)\n",
        "rho_2 = tf.broadcast_to(rho_2, shape=tf.shape(rho_1))\n",
        "prod = layers.DMCrossProduct()([rho_1, rho_2])\n",
        "qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=100, dim_y=10, n_comp=40)\n",
        "rho_y = qmdmc(prod)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v), optimize='optimal')\n",
        "qm_partial = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "qm_partial.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fb4168e4280>,\n",
              " <tensorflow.python.keras.layers.core.SlicingOpLambda at 0x7fb4168e45b0>,\n",
              " <tensorflow.python.keras.engine.functional.Functional at 0x7fb3f127e850>,\n",
              " <tensorflow.python.keras.layers.core.TFOpLambda at 0x7fb41688c130>,\n",
              " <tensorflow.python.keras.layers.core.TFOpLambda at 0x7fb41688c940>,\n",
              " <qmc.tf.layers.DMCrossProduct at 0x7fb3f1283af0>,\n",
              " <qmc.tf.layers.QMClassifSDecompFDMatrix at 0x7fb416892970>,\n",
              " <tensorflow.python.keras.layers.core.SlicingOpLambda at 0x7fb416cfd400>,\n",
              " <tensorflow.python.keras.layers.core.SlicingOpLambda at 0x7fb416cf4610>,\n",
              " <tensorflow.python.keras.layers.core.TFOpLambda at 0x7fb416cfd7c0>,\n",
              " <tensorflow.python.keras.layers.core.TFOpLambda at 0x7fb41688c8b0>]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "qm_partial.layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "qm_partial.layers[2].set_weights(qm_multim.layers[3].get_weights())\n",
        "qm_partial.layers[6].set_weights(qm_multim.layers[6].get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 1.1990 - accuracy: 0.4815\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2016475200653076, 0.4797999858856201]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "qm_partial.evaluate(X_test, y_test_bin)"
      ]
    },
    {
      "source": [
        "## Multimodal with fixed layers"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diEm3hzi31v1"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(784,))\n",
        "clf_1 = create_model_rho(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "clf_2 = create_model_rho(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "rho_1 = clf_1(inputs[:, :784 // 2])\n",
        "rho_2 = clf_2(inputs[:, 784 // 2:])\n",
        "prod = layers.DMCrossProduct()([rho_1, rho_2])\n",
        "qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=100, dim_y=10, n_comp=40)\n",
        "rho_y = qmdmc(prod)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v), optimize='optimal')\n",
        "qm_multim = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "\n",
        "qm_multim.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "qm_multim.layers[3].set_weights(qmdmclf_1.get_weights())\n",
        "qm_multim.layers[3].trainable = False\n",
        "qm_multim.layers[4].set_weights(qmdmclf_2.get_weights())\n",
        "qm_multim.layers[4].trainable = False\n"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "188/188 [==============================] - 25s 125ms/step - loss: 0.6610 - accuracy: 0.8872 - val_loss: 0.1700 - val_accuracy: 0.9712\n",
            "Epoch 2/3\n",
            "188/188 [==============================] - 23s 123ms/step - loss: 0.1328 - accuracy: 0.9821 - val_loss: 0.1558 - val_accuracy: 0.9718\n",
            "Epoch 3/3\n",
            "188/188 [==============================] - 23s 124ms/step - loss: 0.1120 - accuracy: 0.9859 - val_loss: 0.1513 - val_accuracy: 0.9715\n"
          ]
        }
      ],
      "source": [
        "\n",
        "EPOCHS = 3\n",
        "history = qm_multim.fit(X_train, y_train_bin, batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tf.keras.Input(shape=(784,))\n",
        "clf_1 = create_model_rho(784 // 2, 10, num_rff=256, n_comp=20)\n",
        "rho_1 = clf_1(inputs[:, :784 // 2])\n",
        "rho_in = tf.keras.layers.concatenate((tf.ones((1, 256)) / 256., tf.eye(256)), axis = 0)\n",
        "rho_in = tf.expand_dims(rho_in, axis=0)\n",
        "clf_2 = layers.QMClassifSDecompFDMatrix(dim_x=256, dim_y=10, n_comp=20, name=\"clf_2\")\n",
        "clf_2(rho_in)\n",
        "clf_2.set_weights(qm_multim.layers[4].layers[-1].get_weights())\n",
        "rho_2 = clf_2(rho_in)\n",
        "#rho_2 = tf.keras.layers.concatenate((rho_2, tf.zeros((11, 10))), axis=1)\n",
        "rho_2 = tf.broadcast_to(rho_2, shape=tf.shape(rho_1))\n",
        "prod = layers.DMCrossProduct()([rho_1, rho_2])\n",
        "qmdmc = layers.QMClassifSDecompFDMatrix(dim_x=100, dim_y=10, n_comp=40)\n",
        "rho_y = qmdmc(prod)\n",
        "y_w = rho_y[:, 0, :] # shape (b, d_in)\n",
        "y_v = rho_y[:, 1:, :] # shape (b, dim_x, d_in)\n",
        "probs = tf.einsum('...j,...ij,...ij->...i', y_w, y_v, tf.math.conj(y_v), optimize='optimal')\n",
        "qm_partial = tf.keras.Model(inputs=inputs, outputs=probs)\n",
        "qm_partial.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "qm_partial.layers[2].set_weights(qm_multim.layers[3].get_weights())\n",
        "qm_partial.layers[6].set_weights(qm_multim.layers[6].get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 7ms/step - loss: 1.0419 - accuracy: 0.6605\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0419251918792725, 0.6604999899864197]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "qm_partial.evaluate(X_test, y_test_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step - loss: 0.8688 - accuracy: 0.7153\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.868797779083252, 0.7153000235557556]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "qm_multim.evaluate(X_test_noise, y_test_bin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}